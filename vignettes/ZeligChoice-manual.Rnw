\documentclass{article}

\title{blogit: Bivariate Logistic Regression for Two Dichotomous Dependent Variables}
\author{Matt Owen, Olivia Lau, Kosuke Imai, and Gary King}

\SweaveOpts{results=hide, prefix.string=zeligchoice}

\usepackage{bibentry}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{url}
\usepackage{Zelig}
\usepackage{Sweave}

%\VignetteIndexEntry{Bivariate Logistic Regression for Two Dichotomous Dependent Variables}
%\VignetteDepends{ZeligChoice}
%\VignetteKeyWords{model, logit, probit, bivariate, ordinal, multinomial, dichotomous}
%\VignettePackage{ZeligChoice}

\begin{document}

<<loadLibrary, echo=F,results=hide>>=
library(ZeligChoice)
@ 

\section{{\tt blogit}: Bivariate Logistic Regression for Two
Dichotomous Dependent Variables}\label{blogit}

Use the bivariate logistic regression model if you have two binary
dependent variables $(Y_1, Y_2)$, and wish to model them jointly as a
function of some explanatory variables.  Each pair of dependent
variables $(Y_{i1}, Y_{i2})$ has four potential outcomes, $(Y_{i1}=1,
Y_{i2}=1)$, $(Y_{i1}=1, Y_{i2}=0)$, $(Y_{i1}=0, Y_{i2}=1)$, and
$(Y_{i1}=0, Y_{i2}=0)$.  The joint probability for each of these four
outcomes is modeled with three systematic components: the marginal
Pr$(Y_{i1} = 1)$ and Pr$(Y_{i2} = 1)$, and the odds ratio $\psi$,
which describes the dependence of one marginal on the other.  Each of
these systematic components may be modeled as functions of (possibly
different) sets of explanatory variables.

\subsubsection{Syntax}

\begin{verbatim}
> z.out <- zelig(list(mu1 = Y1 ~ X1 + X2 , 
                      mu2 = Y2 ~ X1 + X3), 
                 model = "blogit", data = mydata)
> x.out <- setx(z.out)
> s.out <- sim(z.out, x = x.out)
\end{verbatim}

\subsubsection{Input Values}

In every bivariate logit specification, there are three equations which
correspond to each dependent variable ($Y_1$, $Y_2$), and $\psi$, the
odds ratio. You should provide a list of formulas for each equation or, 
you may use {\tt cbind()} if the right hand side is the same for both equations
<<InputValues.list>>=
formulae <- list(cbind(Y1,Y2) ~ X1 + X2)
@ 
which means that all the explanatory variables in equations 1 and 2
(corresponding to $Y_1$ and $Y_2$) are included, but only an intercept
is estimated (all explanatory variables are omitted) for equation 3
($\psi$).  

You may use the function {\tt tag()} to constrain variables across
equations:
<<InputValues.list.mu>>=
formulae <- list(mu1 = y1 ~ x1 + tag(x3, "x3"), 
                 mu2 = y2 ~ x2 + tag(x3, "x3"))
@ 
where {\tt tag()} is a special function that constrains variables to
have the same effect across equations.  Thus, the coefficient for {\tt
x3} in equation {\tt mu1} is constrained to be equal to the
coefficient for {\tt x3} in equation {\tt mu2}.  

\subsubsection{Examples}

\begin{enumerate}

\item {Basic Example} \label{basic.bl}

Load the data and estimate the model:  
<<BasicExample.data>>=
 data(sanction)
## sanction
@ 
<<BasicExample.zelig>>=
 z.out1 <- zelig(cbind(import, export) ~ coop + cost + target, 
                  model = "blogit", data = sanction)
@ 
By default, {\tt zelig()} estimates two effect parameters
for each explanatory variable in addition to the odds ratio parameter;
this formulation is parametrically independent (estimating
unconstrained effects for each explanatory variable), but
stochastically dependent because the models share an odds ratio.
\newline \newline Generate baseline values for the explanatory
variables (with cost set to 1, net gain to sender) and alternative
values (with cost set to 4, major loss to sender):
<<BasicExample.setx.low>>=
 x.low <- setx(z.out1, cost = 1)
@ 
<<BasicExample.setx.high>>=
x.high <- setx(z.out1, cost = 4)
@ 
Simulate fitted values and first differences:  
<<BasicExample.sim>>=
 s.out1 <- sim(z.out1, x = x.low, x1 = x.high)
 summary(s.out1)
@
\begin{center}
<<label=blogit-BasicExamplePlot,fig=true>>= 
 plot(s.out1)
@ 
\end{center}

\item {Joint Estimation of a Model with Different Sets of Explanatory Variables}\label{sto.dep.logit}

Using sample data \texttt{sanction}, estimate the statistical model, 
with {\tt import} a function of {\tt coop} in the first equation and {\tt export} a 
function of {\tt cost} and {\tt target} in the second equation:
<<JointExample.zelig>>=
 z.out2 <- zelig(list(import ~ coop, export ~ cost + target), 
                  model = "blogit", data = sanction)
 summary(z.out2)
@ 
Set the explanatory variables to their means:
<<JointExample.setx>>=
 x.out2 <- setx(z.out2)
@ 
Simulate draws from the posterior distribution:
<<JointExample.sim>>=
 s.out2 <- sim(z.out2, x = x.out2)
 summary(s.out2)
@ 
\begin{center}
<<label=blogitJointExamplePlot,fig=true>>= 
 plot(s.out2)
@ 
\end{center}

% \item Joint Estimation of a Parametrically and Stochastically
% Dependent Model 
% \label{pdep.l}
%   
% Using the sample data \texttt{sanction}
% The bivariate model is parametrically dependent if $Y_1$ and $Y_2$ share
% some or all explanatory variables, {\it and} the effects of the shared
% explanatory variables are jointly estimated.  For example,
% <<JointEstimation.zelig>>=
%  z.out3 <- zelig(list(import ~ tag(coop,"coop") + tag(cost,"cost") + 
%                            tag(target,"target"), 
%                        export ~ tag(coop,"coop") + tag(cost,"cost") + 
%                            tag(target,"target")), 
%                        model = "blogit", data = sanction)
%  summary(z.out3)
% @ 
% Note that this model only returns one parameter estimate for each of
% {\tt coop}, {\tt cost}, and {\tt target}.  Contrast this to
% Example~\ref{basic.bl} which returns two parameter estimates for each
% of the explanatory variables.  \newline \newline Set values for the
% explanatory variables:
% <<JointEstimation.setx>>=
% x.out3 <- setx(z.out3, cost = 1:4)
% @ 
% Draw simulated expected values:  
% <<JointEstimation.sim>>=
%  s.out3 <- sim(z.out3, x = x.out3)
%  summary(s.out3)
% @ 


\end{enumerate}

\subsubsection{Model}

For each observation, define two binary dependent variables, $Y_1$ and
$Y_2$, each of which take the value of either 0 or 1 (in the
following, we suppress the observation index).  We model the joint
outcome $(Y_1$, $Y_2)$ using a marginal probability for each dependent
variable, and the odds ratio, which parameterizes the relationship
between the two dependent variables. Define $Y_{rs}$ such that it is
equal to 1 when $Y_1=r$ and $Y_2=s$ and is 0 otherwise, where $r$ and
$s$ take a value of either 0 or 1. Then, the model is defined as follows,

\begin{itemize}
 
\item The \emph{stochastic component} is
\begin{eqnarray*}
  Y_{11} &\sim& \textrm{Bernoulli}(y_{11} \mid \pi_{11}) \\
  Y_{10} &\sim& \textrm{Bernoulli}(y_{10} \mid \pi_{10}) \\
  Y_{01} &\sim& \textrm{Bernoulli}(y_{01} \mid \pi_{01})
\end{eqnarray*}
where $\pi_{rs}=\Pr(Y_1=r, Y_2=s)$ is the joint probability, and
$\pi_{00}=1-\pi_{11}-\pi_{10}-\pi_{01}$.


\item The \emph{systematic components} model the marginal probabilities,
  $\pi_j=\Pr(Y_j=1)$, as well as the odds ratio.  The odds ratio
  is defined as $\psi = \pi_{00} \pi_{01}/\pi_{10}\pi_{11}$ and
  describes the relationship between the two outcomes.  Thus, for each
  observation we have
\begin{eqnarray*}
\pi_j & = & \frac{1}{1 + \exp(-x_j \beta_j)} \quad \textrm{ for} \quad
j=1,2, \\
\psi &= & \exp(x_3 \beta_3).
\end{eqnarray*}

\end{itemize}

\subsubsection{Quantities of Interest}
\begin{itemize}
\item The expected values ({\tt qi\$ev}) for the bivariate logit model
  are the predicted joint probabilities. Simulations of $\beta_1$,
  $\beta_2$, and $\beta_3$ (drawn from their sampling distributions)
  are substituted into the systematic components $(\pi_1, \pi_2,
  \psi)$ to find simulations of the predicted joint probabilities:
\begin{eqnarray*}
\pi_{11} & = & \left\{ \begin{array}{ll}
                 \frac{1}{2}(\psi - 1)^{-1} - {a - \sqrt{a^2 + b}} &
                 \textrm{for} \; \psi \ne 1 \\
                 \pi_1 \pi_2 & \textrm{for} \; \psi = 1 
                 \end{array} \right., \\
\pi_{10} &=& \pi_1 - \pi_{11}, \\
\pi_{01} &=& \pi_2 - \pi_{11}, \\
\pi_{00} &=& 1 - \pi_{10} - \pi_{01} - \pi_{11},
\end{eqnarray*}
where $a = 1 + (\pi_1 + \pi_2)(\psi - 1)$, $b = -4 \psi(\psi - 1)
\pi_1 \pi_2$, and the joint probabilities for each observation must sum
to one.  For $n$ simulations, the expected values form an $n \times 4$
matrix for each observation in {\tt x}.  

\item The predicted values ({\tt qi\$pr}) are draws from the
  multinomial distribution given the expected joint probabilities. 

\item The first differences ({\tt qi\$fd}) for each
  of the predicted joint probabilities are given by $$\textrm{FD}_{rs}
  = \Pr(Y_1=r, Y_2=s \mid x_1)-\Pr(Y_1=r, Y_2=s \mid x).$$  
  
\item The risk ratio ({\tt qi\$rr}) for each of the predicted joint
  probabilities are given by
\begin{equation*}
\textrm{RR}_{rs} = \frac{\Pr(Y_1=r, Y_2=s \mid x_1)}{\Pr(Y_1=r, Y_2=s \mid x)}
\end{equation*}

\item In conditional prediction models, the average expected treatment
  effect ({\tt att.ev}) for the treatment group is 
    \begin{equation*} \frac{1}{\sum_{i=1}^n t_i}\sum_{i:t_i=1}^n \left\{ Y_{ij}(t_i=1) -
      E[Y_{ij}(t_i=0)] \right\} \textrm{ for } j = 1,2,
    \end{equation*} 
    where $t_i$ is a binary explanatory variable defining the treatment
    ($t_i=1$) and control ($t_i=0$) groups.  Variation in the
    simulations are due to uncertainty in simulating $E[Y_{ij}(t_i=0)]$,
    the counterfactual expected value of $Y_{ij}$ for observations in the
    treatment group, under the assumption that everything stays the
    same except that the treatment indicator is switched to $t_i=0$.

\item In conditional prediction models, the average predicted treatment
  effect ({\tt att.pr}) for the treatment group is 
    \begin{equation*} \frac{1}{\sum_{i=1}^n t_i}\sum_{i:t_i=1}^n \left\{ Y_{ij}(t_i=1) -
      \widehat{Y_{ij}(t_i=0)} \right\} \textrm{ for } j = 1,2,
    \end{equation*} 
    where $t_i$ is a binary explanatory variable defining the treatment
    ($t_i=1$) and control ($t_i=0$) groups.  Variation in the
    simulations are due to uncertainty in simulating
    $\widehat{Y_{ij}(t_i=0)}$, the counterfactual predicted value of
    $Y_{ij}$ for observations in the treatment group, under the
    assumption that everything stays the same except that the
    treatment indicator is switched to $t_i=0$.
\end{itemize}

\subsubsection{Output Values}

The output of each Zelig command contains useful information which you
may view.  For example, if you run \texttt{z.out <- zelig(y \~\,
  x, model = "blogit", data)}, then you may examine the available
information in \texttt{z.out} by using \texttt{names(z.out)},
see the {\tt coefficients} by using {\tt z.out\$coefficients}, and
obtain a default summary of information through {\tt summary(z.out)}.
Other elements available through the {\tt \$} operator are listed
below.

\begin{itemize}
\item From the {\tt zelig()} output object {\tt z.out}, you may
  extract:
   \begin{itemize}
   \item {\tt coefficients}: the named vector of coefficients.   
   \item {\tt fitted.values}: an $n \times 4$ matrix of the in-sample
     fitted values.
   \item {\tt predictors}: an $n \times 3$ matrix of the linear
     predictors $x_j \beta_j$.
   \item {\tt residuals}: an $n \times 3$ matrix of the residuals.  
   \item {\tt df.residual}: the residual degrees of freedom.  
   \item {\tt df.total}: the total degrees of freedom.
   \item {\tt rss}: the residual sum of squares.  
   \item {\tt y}: an $n \times 2$ matrix of the dependent variables.
   \item {\tt zelig.data}: the input data frame if {\tt save.data = TRUE}.  
   \end{itemize}

\item From {\tt summary(z.out)}, you may extract:
  \begin{itemize}
  \item {\tt coef3}: a table of the coefficients with their associated
    standard errors and $t$-statistics.
  \item {\tt cov.unscaled}: the variance-covariance matrix. 
  \item {\tt pearson.resid}: an $n \times 3$ matrix of the Pearson residuals.  
  \end{itemize}

\item From the {\tt sim()} output object {\tt s.out}, you may extract
  quantities of interest arranged as arrays indexed by simulation
  $\times$ quantity $\times$ {\tt x}-observation (for more than one
  {\tt x}-observation; otherwise the quantities are matrices).
  Available quantities are:

   \begin{itemize}
   \item {\tt qi\$ev}: the simulated expected joint probabilities (or expected
     values) for the specified values of {\tt x}.  
   \item {\tt qi\$pr}: the simulated predicted outcomes drawn from a
     distribution defined by the expected joint probabilities.
   \item {\tt qi\$fd}: the simulated first difference in the
     expected joint probabilities for the values specified in {\tt x} and
     {\tt x1}.
   \item {\tt qi\$rr}: the simulated risk ratio in the predicted
     probabilities for given {\tt x} and {\tt x1}.
   \item {\tt qi\$att.ev}: the simulated average expected treatment
     effect for the treated from conditional prediction models.  
   \item {\tt qi\$att.pr}: the simulated average predicted treatment
     effect for the treated from conditional prediction models.  
   \end{itemize}
\end{itemize}

\subsection*{How to Cite the Bivariate Logit Model}
\bibentry{ImaLauKin-blogit11}

\subsection*{How to Cite the Zelig Software Package}
\CiteZelig

\subsection*{See also}
The bivariate logit function is part of the VGAM package by Thomas Yee \citep{YeeHas03}. In addition, advanced users may wish to refer to \texttt{help(vglm)} 
in the VGAM library.  Additional documentation is available at
\hlink{http://www.stat.auckland.ac.nz/\~\,yee}{http://www.stat.auckland.ac.nz/~yee}.Sample data are from \cite{Martin92}

\section{{\tt bprobit}: Bivariate Probit Regression for Two
Dichotomous Dependent Variables}\label{bprobit}

Use the bivariate probit regression model if you have two binaryrun
dependent variables $(Y_1, Y_2)$, and wish to model them jointly as a
function of some explanatory variables.  Each pair of dependent
variables $(Y_{i1}, Y_{i2})$ has four potential outcomes, $(Y_{i1}=1,
Y_{i2}=1)$, $(Y_{i1}=1, Y_{i2}=0)$, $(Y_{i1}=0, Y_{i2}=1)$, and
$(Y_{i1}=0, Y_{i2}=0)$.  The joint probability for each of these four
outcomes is modeled with three systematic components: the marginal
Pr$(Y_{i1} = 1)$ and Pr$(Y_{i2} = 1)$, and the correlation parameter
$\rho$ for the two marginal distributions.  Each of these systematic
components may be modeled as functions of (possibly different) sets of
explanatory variables.

\subsubsection{Syntax}

\begin{verbatim}
> z.out <- zelig(list(mu1 = Y1 ~ X1 + X2, 
                      mu2 = Y2 ~ X1 + X3,
                      rho = ~ 1),
                 model = "bprobit", data = mydata)
> x.out <- setx(z.out)
> s.out <- sim(z.out, x = x.out)
\end{verbatim}

\subsubsection{Input Values}

In every bivariate probit specification, there are three equations
which correspond to each dependent variable ($Y_1$, $Y_2$), and the
correlation parameter $\rho$.  Since the correlation parameter does
not correspond to one of the dependent variables, the model estimates
$\rho$ as a constant by default.  Hence, only two formulas (for
$\mu_1$ and $\mu_2$) are required.  If the explanatory variables for
$\mu_1$ and $\mu_2$ are the same and effects are estimated separately
for each parameter, you may use the following short hand:  
<<InputValues.list>>=
fml <- list(cbind(Y1,Y2) ~ X1 + X2)
@ 
which has the same meaning as:  
<<InputValues.list.rho>>=
fml <- list(mu1 = Y1 ~ X1 + X2,  
            mu2 = Y2 ~ X1 + X2, 
            rho = ~ 1)
@ 
You may use the function {\tt tag()} to constrain variables across
equations.  The {\tt tag()} function takes a variable and a label for
the effect parameter.  Below, the constrained effect of {\tt
x3} in both equations is called the {\tt age} parameter:  
<<InputValues.list.mu>>=
fml <- list(mu1 = y1 ~ x1 + tag(x3, "age"), 
            mu2 = y2 ~ x2 + tag(x3, "age"))
@ 
You may also constrain different variables across different equations
to have the same effect.  

\subsubsection{Examples}

\begin{enumerate}

\item {Basic Example} \label{basic.bp}

Load the data and estimate the model:  
<<BasicExample.data>>=
 data(sanction)
@ 
<<BasicExample.zelig>>=
 z.out1 <- zelig(cbind(import, export) ~ coop + cost + target, 
                  model = "bprobit", data = sanction)
@ 
By default, {\tt zelig()} estimates two effect parameters
for each explanatory variable in addition to the correlation coefficient;
this formulation is parametrically independent (estimating
unconstrained effects for each explanatory variable), but
stochastically dependent because the models share a correlation parameter.
\newline \newline Generate baseline values for the explanatory
variables (with cost set to 1, net gain to sender) and alternative
values (with cost set to 4, major loss to sender):
<<BasicExample.setx>>=
 x.low <- setx(z.out1, cost = 1)
 x.high <- setx(z.out1, cost = 4)
@ 
Simulate fitted values and first differences:  
<<BasicExample.sim>>=
 s.out1 <- sim(z.out1, x = x.low, x1 = x.high)
 summary(s.out1)
@ 
\begin{center}
<<label=bprobit-BasicExamplePlot,fig=true>>= 
 plot(s.out1)
@ 
\end{center}


\item {Joint Estimation of a Model with Different Sets of Explanatory Variables}\label{sto.dep.probit}

Using the sample data \texttt{sanction}, estimate the statistical model, 
with {\tt import} a function of {\tt coop} in the first equation and 
{\tt export} a function of {\tt cost} and {\tt target} in the second equation:
<<JointEstimation.list>>=
 fml2 <- list(mu1 = import ~ coop, 
               mu2 = export ~ cost + target)
@ 
<<JointEstimation.zelig>>=
 z.out2 <- zelig(fml2, model = "bprobit", data = sanction)
 summary(z.out2)
@ 
Set the explanatory variables to their means:
<<JointEstimation.setx>>=
 x.out2 <- setx(z.out2)
@ 
Simulate draws from the posterior distribution:
<<JointEstimation.sim>>=
 s.out2 <- sim(z.out2, x = x.out2)
 summary(s.out2)
@
\begin{center}
<<label=bprobit-JointEstimationPlot,fig=true>>= 
 plot(s.out2)
@ 
\end{center}


% \item Joint Estimation of a Parametrically and Stochastically
% Dependent Model 
% \label{pdep.p}
%   
% Using the sample data \texttt{sanction}.     
% The bivariate model is parametrically dependent if $Y_1$ and $Y_2$ share
% some or all explanatory variables, {\it and} the effects of the shared
% explanatory variables are jointly estimated.  For example,
% <<JointEstimationParam.list>>= 
%  fml3 <- list(mu1 = import ~ tag(coop,"coop") + tag(cost,"cost") + 
%                           tag(target,"target"), 
%                mu2 = export ~ tag(coop,"coop") + tag(cost,"cost") + 
%                           tag(target,"target"))
% @ 
% <<JointEstimationParam.zelig>>= 
%  z.out3 <- zelig(fml3, model = "bprobit", data = sanction)
%  summary(z.out3)
% @ 
% 
% Note that this model only returns one parameter estimate for each of
% {\tt coop}, {\tt cost}, and {\tt target}.  Contrast this to
% Example~\ref{basic.bp} which returns two parameter estimates for each
% of the explanatory variables.  \newline \newline Set values for the
% explanatory variables:
% <<JointEstimationParam.setx>>= 
%  x.out3 <- setx(z.out3, cost = 1:4)
% @ 
% Draw simulated expected values:  
% <<JointEstimationParam.sim>>= 
%  s.out3 <- sim(z.out3, x = x.out3)
%  summary(s.out3)
% @ 

\end{enumerate}

\subsubsection{Model}

For each observation, define two binary dependent variables, $Y_1$ and
$Y_2$, each of which take the value of either 0 or 1 (in the
following, we suppress the observation index $i$).  We model the joint
outcome $(Y_1$, $Y_2)$ using two marginal probabilities for each
dependent variable, and the correlation parameter, which describes how
the two dependent variables are related. 
%Define $Y_{rs}$ such that it
%is equal to 1 when $Y_1=r$ and $Y_2=s$ and is 0 otherwise where $r$
%and $s$ take a value of either 0 or 1. Then, the model is defined as
%follows,

\begin{itemize}
\item The \emph{stochastic component} is described by two latent (unobserved)
  continuous variables which follow the bivariate Normal distribution:
\begin{eqnarray*}
  \left ( \begin{array}{c} 
      Y_1^* \\
      Y_2^* 
    \end{array}
  \right ) &\sim &  
  N_2 \left \{ \left ( 
      \begin{array}{c}
        \mu_1 \\ \mu_2
      \end{array} \right ), \left( \begin{array}{cc}
                 1 & \rho \\
                 \rho & 1 
                 \end{array} \right) \right\},
\end{eqnarray*}
where $\mu_j$ is a mean for $Y_j^*$ and $\rho$ is a scalar correlation
parameter. The following observation mechanism links the observed
dependent variables, $Y_j$, with these latent variables
\begin{eqnarray*}
Y_j & = & \left \{ \begin{array}{cc}
                   1 & {\rm if} \; Y_j^* \ge 0, \\
                   0 & {\rm otherwise.}
                   \end{array} 
                   \right.
\end{eqnarray*}

%Alternatively, the stochastic component for the observed dependent
%variables can be written as
%\begin{eqnarray*}
%  Y_{11} &\sim& \textrm{Bernoulli}(y_{11} \mid \pi_{11}) \\
%  Y_{10} &\sim& \textrm{Bernoulli}(y_{10} \mid \pi_{10}) \\
% Y_{01} &\sim& \textrm{Bernoulli}(y_{01} \mid \pi_{01})
%\end{eqnarray*}
%where $\pi_{rs}=\Pr(Y_1=r, Y_2=s)$ is the joint probability, and
%$\pi_{00}=1-\pi_{11}-\pi_{10}-\pi_{01}$. Each of these joint
%probabilities is modeled using the bivariate normal cumulative
%distribution function.

\item The \emph{systemic components} for each observation are 
  \begin{eqnarray*}
    \mu_j & = & x_{j} \beta_j \quad {\rm for} \quad j=1,2, \\
    \rho & = & \frac{\exp(x_3 \beta_3) - 1}{\exp(x_3 \beta_3) + 1}.
\end{eqnarray*}

\end{itemize}

\subsubsection{Quantities of Interest}
For $n$ simulations, expected values form an $n \times 4$
matrix.  
\begin{itemize}
\item The expected values ({\tt qi\$ev}) for the binomial probit model
  are the predicted joint probabilities. Simulations of $\beta_1$,
  $\beta_2$, and $\beta_3$ (drawn form their sampling distributions)
  are substituted into the systematic components, to find simulations
  of the predicted joint probabilities $\pi_{rs}=\Pr(Y_1=r, Y_2=s)$:
\begin{eqnarray*}
\pi_{11} &= \Pr(Y_1^* \geq 0 , Y_2^* \geq 0) &= \int_0^{\infty}
\int_0^{\infty} \phi_2 (\mu_1, \mu_2, \rho) \, dY_2^*\, dY_1^* \\
\pi_{10} &= \Pr(Y_1^* \geq 0 , Y_2^* < 0)  &= \int_0^{\infty}
\int_{-\infty}^{0} \phi_2 (\mu_1, \mu_2, \rho) \, dY_2^*\, dY_1^*\\
\pi_{01} &= \Pr(Y_1^* < 0 , Y_2^* \geq 0)  &= \int_{-\infty}^{0}
\int_0^{\infty} \phi_2 (\mu_1, \mu_2, \rho) \, dY_2^*\, dY_1^*\\
\pi_{11} &= \Pr(Y_1^* < 0 , Y_2^* < 0)  &= \int_{-\infty}^{0}
\int_{-\infty}^{0} \phi_2 (\mu_1, \mu_2, \rho) \, dY_2^*\, dY_1^*\\
\end{eqnarray*}
where $r$ and $s$ may take a value of either 0 or 1, $\phi_2$ is the
bivariate Normal density.
  
\item The predicted values ({\tt qi\$pr}) are draws from the
  multinomial distribution given the expected joint probabilities.  

\item The first difference ({\tt qi\$fd}) in each of the predicted joint
  probabilities are given by
  $$\textrm{FD}_{rs} = \Pr(Y_1=r, Y_2=s \mid x_1)-\Pr(Y_1=r, Y_2=s
  \mid x).$$
  
\item The risk ratio ({\tt qi\$rr}) for each of the predicted joint
  probabilities are given by
\begin{equation*}
\textrm{RR}_{rs} = \frac{\Pr(Y_1=r, Y_2=s \mid x_1)}{\Pr(Y_1=r, Y_2=s \mid x)}.
\end{equation*}

\item In conditional prediction models, the average expected treatment
  effect ({\tt att.ev}) for the treatment group is 
    \begin{equation*} \frac{1}{\sum_{i=1}^n t_i}\sum_{i:t_i=1}^n \left\{ Y_{ij}(t_i=1) -
      E[Y_{ij}(t_i=0)] \right\} \textrm{ for } j = 1,2,
    \end{equation*} 
    where $t_i$ is a binary explanatory variable defining the treatment
    ($t_i=1$) and control ($t_i=0$) groups.  Variation in the
    simulations are due to uncertainty in simulating $E[Y_{ij}(t_i=0)]$,
    the counterfactual expected value of $Y_{ij}$ for observations in the
    treatment group, under the assumption that everything stays the
    same except that the treatment indicator is switched to $t_i=0$.

\item In conditional prediction models, the average predicted treatment
  effect ({\tt att.pr}) for the treatment group is 
    \begin{equation*} \frac{1}{\sum_{i=1}^n t_i}\sum_{i:t_i=1}^n \left\{ Y_{ij}(t_i=1) -
      \widehat{Y_{ij}(t_i=0)}\right\} \textrm{ for } j = 1,2,
    \end{equation*} 
    where $t_i$ is a binary explanatory variable defining the treatment
    ($t_i=1$) and control ($t_i=0$) groups.  Variation in the
    simulations are due to uncertainty in simulating
    $\widehat{Y_{ij}(t_i=0)}$, the counterfactual predicted value of
    $Y_{ij}$ for observations in the treatment group, under the
    assumption that everything stays the same except that the
    treatment indicator is switched to $t_i=0$.

\end{itemize}

\subsubsection{Output Values}

The output of each Zelig command contains useful information which you
may view.  For example, if you run \texttt{z.out <- zelig(y \~\, x,
  model = "bprobit", data)}, then you may examine the available
information in \texttt{z.out} by using \texttt{names(z.out)},
see the {\tt coefficients} by using {\tt z.out\$coefficients}, and
obtain a default summary of information through
\texttt{summary(z.out)}.  Other elements available through the {\tt
  \$} operator are listed below.

\begin{itemize}
\item From the {\tt zelig()} output object {\tt z.out}, you may
  extract:
   \begin{itemize}
   \item {\tt coefficients}: the named vector of coefficients.   
   \item {\tt fitted.values}: an $n \times 4$ matrix of the in-sample
     fitted values.
   \item {\tt predictors}: an $n \times 3$ matrix of the linear
     predictors $x_j \beta_j$.
   \item {\tt residuals}: an $n \times 3$ matrix of the residuals.  
   \item {\tt df.residual}: the residual degrees of freedom.  
   \item {\tt df.total}: the total degrees of freedom.
   \item {\tt rss}: the residual sum of squares.  
   \item {\tt y}: an $n \times 2$ matrix of the dependent variables.  
   \item {\tt zelig.data}: the input data frame if {\tt save.data = TRUE}.  
   \end{itemize}

\item From {\tt summary(z.out)}, you may extract:
\begin{itemize}
  \item {\tt coef3}: a table of the coefficients with their associated
    standard errors and $t$-statistics.
  \item {\tt cov.unscaled}: the variance-covariance matrix. 
  \item {\tt pearson.resid}: an $n \times 3$ matrix of the Pearson residuals.  
\end{itemize}

\item From the {\tt sim()} output object {\tt s.out}, you may extract
  quantities of interest arranged as arrays indexed by simulation
  $\times$ quantity $\times$ {\tt x}-observation (for more than one
  {\tt x}-observation; otherwise the quantities are matrices).  Available quantities
  are:  

   \begin{itemize}
   \item {\tt qi\$ev}: the simulated expected values (joint predicted
     probabilities) for the specified values of {\tt x}.
   \item {\tt qi\$pr}: the simulated predicted outcomes drawn from a
     distribution defined by the joint predicted probabilities.
   \item {\tt qi\$fd}: the simulated first difference in the predicted
     probabilities for the values specified in {\tt x} and {\tt x1}.
   \item {\tt qi\$rr}: the simulated risk ratio in the predicted
     probabilities for given {\tt x} and {\tt x1}.
   \item {\tt qi\$att.ev}: the simulated average expected treatment
     effect for the treated from conditional prediction models.  
   \item {\tt qi\$att.pr}: the simulated average predicted treatment
     effect for the treated from conditional prediction models.  
   \end{itemize}
\end{itemize}

\subsection*{How to Cite the Bivariate Probit Model}
\bibentry{ImaLauKin-bprobit11}

\subsection*{How to Cite the Zelig Software Package}
\CiteZelig


\subsection*{See also}
The bivariate probit function is part of the VGAM package by Thomas Yee \citep{YeeHas03}. In addition, advanced users may wish to refer to \texttt{help(vglm)} 
in the VGAM library.  Additional documentation is available at
\hlink{http://www.stat.auckland.ac.nz/\~\,yee}{http://www.stat.auckland.ac.nz/~yee}.Sample data are from \cite{Martin92}

\section{{\tt ologit}: Ordinal Logistic Regression for Ordered Categorical Dependent Variables}
\label{ologit}

Use the ordinal logit regression model if your dependent variable is
ordered and categorical, either in the form of integer values or character strings.  

\subsubsection{Syntax}

\begin{verbatim}
> z.out <- zelig(as.factor(Y) ~ X1 + X2, model = "ologit", data = mydata)
> x.out <- setx(z.out)
> s.out <- sim(z.out, x = x.out)
\end{verbatim}
If {\tt Y} takes discrete integer values, the {\tt as.factor()}
command will order automatically order the values.  If {\tt Y} takes
on values composed of character strings, such as ``strongly agree'',
``agree'', and ``disagree'', {\tt as.factor()} will order the values
in the order in which they appear in {\tt Y}.  You will need to
replace your dependent variable with a factored variable prior to
estimating the model through {\tt zelig()}.  See Example
\ref{ord.fact} for more information on creating ordered factors.

\subsubsection{Example}

\begin{enumerate}

\item {Creating An Ordered Dependent Variable} \label{ord.fact}

Load the sample data:  
<<Example.data>>=
 data(sanction)
@ 
Create an ordered dependent variable: 
<<Example.factor>>=
 sanction$ncost <- factor(sanction$ncost, ordered = TRUE,
                          levels = c("net gain", "little effect", 
                          "modest loss", "major loss"))
@ 
Estimate the model:
<<Example.zelig>>=
 z.out <- zelig(ncost ~ mil + coop, model = "ologit", data = sanction)
@ 
Set the explanatory variables to their observed values:  
<<Example.setx>>=
 x.out <- setx(z.out, fn = NULL)
@ 
Simulate fitted values given {\tt x.out} and view the results:
<<Example.sim>>=
 s.out <- sim(z.out, x = x.out)
@
<<Example.summary>>= 
 summary(s.out)
@ 

\item {First Differences}

Using the sample data \texttt{sanction}, estimate the empirical model and returning the coefficients:
<<FirstDifferences.zelig>>=
 z.out <- zelig(as.factor(cost) ~ mil + coop, model = "ologit", 
                 data = sanction)
@ 
<<FirstDifferences.summary>>=
summary(z.out)
@ 
Set the explanatory variables to their means, with {\tt mil} set
to 0 (no military action in addition to sanctions) in the baseline
case and set to 1 (military action in addition to sanctions) in the
alternative case:
<<FirstDifferences.setx>>=
 x.low <- setx(z.out, mil = 0)
 x.high <- setx(z.out, mil = 1)
@ 
Generate simulated fitted values and first differences, and view the results:
<<FirstDifferences.sim>>=
 s.out <- sim(z.out, x = x.low, x1 = x.high)
 summary(s.out)
@ 
\end{enumerate}

\subsubsection{Model}

Let $Y_i$ be the ordered categorical dependent variable for
observation $i$ that takes one of the integer values from $1$ to $J$
where $J$ is the total number of categories.
  
\begin{itemize}
\item The \emph{stochastic component} begins with an unobserved continuous
  variable, $Y^*_i$, which follows the standard logistic distribution
  with a parameter $\mu_i$,
  \begin{equation*}
    Y_i^* \; \sim \; \textrm{Logit}(y_i^* \mid \mu_i),  
  \end{equation*}
  to which we add an observation mechanism
  \begin{equation*}
    Y_i \; = \; j \quad {\rm if} \quad \tau_{j-1} \le Y_i^* \le \tau_j
    \quad {\rm for} \quad j=1,\dots,J.
  \end{equation*}
  where $\tau_l$ (for $l=0,\dots,J$) are the threshold parameters with
  $\tau_l < \tau_m$ for all $l<m$ and $\tau_0=-\infty$ and
  $\tau_J=\infty$.
  
\item The \emph{systematic component} has the following form, given
  the parameters $\tau_j$ and $\beta$, and the explanatory variables $x_i$: 
  \begin{equation*}
    \Pr(Y \le j) \; = \; \Pr(Y^* \le \tau_j) \; = \frac{\exp(\tau_j -
      x_i \beta)}{1+\exp(\tau_j -x_i \beta)},
  \end{equation*}
  which implies:
  \begin{equation*}
    \pi_{j}  \; = \; \frac{\exp(\tau_j - x_i \beta)}{1 + \exp(\tau_j -
      x_i \beta)} - \frac{\exp(\tau_{j-1} - x_i \beta)}{1 +
      \exp(\tau_{j-1} - x_i \beta)}.
  \end{equation*}
\end{itemize}

\subsubsection{Quantities of Interest} 

\begin{itemize}
\item The expected values ({\tt qi\$ev}) for the ordinal logit model
  are simulations of the predicted probabilities for each category: 
\begin{equation*}
E(Y = j) \; = \; \pi_{j} \; = \; \frac{\exp(\tau_j - x_i \beta)}
{1 + \exp(\tau_j - x_i \beta)} - \frac{\exp(\tau_{j-1} - x_i \beta)}{1 +
 \exp(\tau_{j-1} - x_i \beta)},
\end{equation*}
given a draw of $\beta$ from its sampling distribution.  

\item The predicted value ({\tt qi\$pr}) is drawn from the logit
  distribution described by $\mu_i$, and observed as one of $J$
  discrete outcomes.  

\item The difference in each of the predicted probabilities ({\tt
    qi\$fd}) is given by
  \begin{equation*}
    \Pr(Y=j \mid x_1) \;-\; \Pr(Y=j \mid x) \quad {\rm for} \quad
    j=1,\dots,J.
  \end{equation*}

\item In conditional prediction models, the average expected treatment
  effect ({\tt att.ev}) for the treatment group is 
    \begin{equation*} \frac{1}{n_j}\sum_{i:t_i=1}^{n_j} \left\{ Y_i(t_i=1) -
      E[Y_i(t_i=0)] \right\},
    \end{equation*} 
where $t_{i}$ is a binary explanatory variable defining the treatment
($t_{i}=1$) and control ($t_{i}=0$) groups, and $n_j$ is the 
number of treated observations in category $j$.

\item In conditional prediction models, the average predicted treatment
  effect ({\tt att.pr}) for the treatment group is 
    \begin{equation*} \frac{1}{n_j}\sum_{i:t_i=1}^{n_j} \left\{ Y_i(t_i=1) -
      \widehat{Y_i(t_i=0)} \right\},
    \end{equation*} 
where $t_{i}$ is a binary explanatory variable defining the treatment
($t_{i}=1$) and control ($t_{i}=0$) groups, and $n_j$ is the 
number of treated observations in category $j$.

\end{itemize}

\subsubsection{Output Values}

The output of each Zelig command contains useful information which you
may view.  For example, if you run \texttt{z.out <- zelig(y \~\,
  x, model = "ologit", data)}, then you may examine the available
information in \texttt{z.out} by using \texttt{names(z.out)},
see the {\tt coefficients} by using {\tt z.out\$coefficients}, and
a default summary of information through \texttt{summary(z.out)}.
Other elements available through the {\tt \$} operator are listed
below.

\begin{itemize}
\item From the {\tt zelig()} output object {\tt z.out}, you may
  extract:
   \begin{itemize}
   \item {\tt coefficients}: parameter estimates for the explanatory
     variables.
   \item {\tt zeta}: a vector containing the estimated class
     boundaries $\tau_j$.
   \item {\tt deviance}: the residual deviance.
   \item {\tt fitted.values}: the $n \times J$ matrix of in-sample
     fitted values.
   \item {\tt df.residual}: the residual degrees of freedom.
   \item {\tt edf}: the effective degrees of freedom.  
   \item {\tt Hessian}: the Hessian matrix.
   \item {\tt zelig.data}: the input data frame if {\tt save.data = TRUE}.  
   \end{itemize}

\item From {\tt summary(z.out)}, you may extract: 
   \begin{itemize}
   \item {\tt coefficients}: the parameter estimates with their
     associated standard errors, and $t$-statistics.
   \end{itemize}
   
 \item From the {\tt sim()} output object {\tt s.out}, you may extract
   quantities of interest arranged as arrays.  Available quantities
   are:

   \begin{itemize}
   \item {\tt qi\$ev}: the simulated expected probabilities for the
     specified values of {\tt x}, indexed by simulation $\times$
     quantity $\times$ {\tt x}-observation (for more than one {\tt
       x}-observation).
   \item {\tt qi\$pr}: the simulated predicted values drawn from the
     distribution defined by the expected probabilities, indexed by
     simulation $\times$ {\tt x}-observation.
   \item {\tt qi\$fd}: the simulated first difference in the predicted
     probabilities for the values specified in {\tt x} and {\tt x1},
     indexed by simulation $\times$ quantity $\times$ {\tt
       x}-observation (for more than one {\tt x}-observation).
   \item {\tt qi\$att.ev}: the simulated average expected treatment
     effect for the treated from conditional prediction models.  
   \item {\tt qi\$att.pr}: the simulated average predicted treatment
     effect for the treated from conditional prediction models.  
   \end{itemize}
\end{itemize}

\subsection*{How to Cite the Ordinal Logit Model}
\bibentry{ImaLauKin-ologit11}

\subsection*{How to Cite the Zelig Software Package}
\CiteZelig

\subsection* {See also}
The ordinal logit model is part of the MASS package by William N. Venable and Brian D. Ripley \citep{VenRip02}. Advanced users may wish to refer to \texttt{help(polr)} as well as \cite{McCNel89}. Sample data are from \cite{Martin92}.



\section{{\tt oprobit}: Ordinal Probit Regression for Ordered
Categorical Dependent Variables}\label{oprobit}

Use the ordinal probit regression model if your dependent variables
are ordered and categorical.  They may take on either integer values
or character strings.  

\subsubsection{Syntax}

\begin{verbatim}
> z.out <- zelig(as.factor(Y) ~ X1 + X2, model = "oprobit", data = mydata)
> x.out <- setx(z.out)
> s.out <- sim(z.out, x = x.out)
\end{verbatim}
If {\tt Y} takes discrete integer values, the {\tt as.factor()}
command will order it automatically.  If {\tt Y} takes on values
composed of character strings, such as ``strongly agree'', ``agree'',
and ``disagree'', {\tt as.factor()} will order the values in the order
in which they appear in {\tt Y}.  You will need to replace your
dependent variable with a factored variable prior to estimating the
model through {\tt zelig()}.
\subsubsection{Example}
\begin{enumerate}
\item {Creating An Ordered Dependent Variable} \label{ord.fact.p}

Load the sample data:  
<<Example.data>>=
 data(sanction)
@ 
Create an ordered dependent variable: 
<<Example.factor>>=
 sanction$ncost <- factor(sanction$ncost, ordered = TRUE,
                           levels = c("net gain", "little effect", 
                           "modest loss", "major loss"))
@
Estimate the model:
<<Example.zelig>>=
 z.out <- zelig(ncost ~ mil + coop, model = "oprobit", data = sanction)
 summary(z.out)
@ 
Set the explanatory variables to their observed values:  
<<Example.setx>>=
 x.out <- setx(z.out, fn = NULL)
@ 
Simulate fitted values given {\tt x.out} and view the results:
<<Example.sim>>=
 s.out <- sim(z.out, x = x.out)
 summary(s.out)
@
%plot does not work but is nnot included in the demo 
\begin{center}
<<label=oprobit-ExamplePlot,fig=true,echo=false>>= 
plot(s.out)
@ 
\end{center}

\item {First Differences}

Using the sample data \texttt{sanction}, let us estimate the empirical model and return the coefficients:
<<FirstDifferences.zelig>>=
 z.out <- zelig(as.factor(cost) ~ mil + coop, model = "oprobit", 
                 data = sanction)
@ 
<<FirstDifferences.summary>>=
summary(z.out)
@ 
Set the explanatory variables to their means, with {\tt mil} set
to 0 (no military action in addition to sanctions) in the baseline
case and set to 1 (military action in addition to sanctions) in the
alternative case:
<<FirstDifferences.setx>>=
 x.low <- setx(z.out, mil = 0)
 x.high <- setx(z.out, mil = 1)
@ 
Generate simulated fitted values and first differences, and view the results:
<<FirstDifferences.sim>>=
 s.out <- sim(z.out, x = x.low, x1 = x.high)
@ 
<<FirstDifferences.summary.sim>>= 
summary(s.out)
@
\begin{center}
<<label=oprobit-FirstDifferencesPlot,fig=true,echo=true>>= 
 plot(s.out)
@ 
\end{center}
\end{enumerate}

\subsubsection{Model}
  Let $Y_i$ be the ordered categorical dependent variable for
  observation $i$ that takes one of the integer values from $1$ to $J$
  where $J$ is the total number of categories.
\begin{itemize}
\item The \emph{stochastic component} is described by an unobserved continuous
  variable, $Y^*_i$, which follows the normal distribution with mean
  $\mu_i$ and unit variance
  \begin{equation*}
    Y_i^* \; \sim \; N(\mu_i, 1). 
  \end{equation*}
  The observation mechanism is 
  \begin{equation*}
    Y_i \; = \; j \quad {\rm if} \quad \tau_{j-1} \le Y_i^* \le \tau_j
    \quad {\rm for} \quad j=1,\dots,J.
  \end{equation*}
  where $\tau_k$ for $k=0,\dots,J$ is the threshold parameter with the
  following constraints; $\tau_l < \tau_m$ for all $l<m$ and
  $\tau_0=-\infty$ and $\tau_J=\infty$.
  
  Given this observation mechanism, the probability for each category,
  is given by
  \begin{equation*}
    \Pr(Y_i = j) \; = \; \Phi(\tau_{j} \mid \mu_i) - \Phi(\tau_{j-1} \mid
    \mu_i) \quad {\rm for} \quad j=1,\dots,J
  \end{equation*}
  where $\Phi(\mu_i)$ is the cumulative distribution function for the
  Normal distribution with mean $\mu_i$ and unit variance.
  
\item The \emph{systematic component} is given by
  \begin{equation*}
    \mu_i \; = \; x_i \beta
  \end{equation*}
  where $x_i$ is the vector of explanatory variables and $\beta$ is
  the vector of coefficients.
\end{itemize}

\subsubsection{Quantities of Interest} 

\begin{itemize}
\item The expected values ({\tt qi\$ev}) for the ordinal probit model
  are simulations of the predicted probabilities for each category:
\begin{equation*}
    E(Y_i = j) \; = \; \Pr(Y_i = j) \; = \; \Phi(\tau_{j} \mid \mu_i)
    - \Phi(\tau_{j-1} \mid  \mu_i) \quad {\rm for} \quad j=1,\dots,J, 
\end{equation*}
given draws of $\beta$ from its posterior.
  
\item The predicted value ({\tt qi\$pr}) is the observed value of
  $Y_i$ given the underlying standard normal distribution described by
  $\mu_i$.

\item The difference in each of the predicted probabilities ({\tt
    qi\$fd}) is given by
  \begin{equation*}
    \Pr(Y=j \mid x_1) \;-\; \Pr(Y=j \mid x) \quad {\rm for} \quad
    j=1,\dots,J.
  \end{equation*}

\item In conditional prediction models, the average expected treatment effect
(\texttt{qi\$att.ev}) for the treatment group in category $j$ is
\begin{eqnarray*}
\frac{1}{n_j}\sum_{i:t_{i}=1}^{n_j}[Y_{i}(t_{i}=1)-E[Y_{i}(t_{i}=0)]],
\end{eqnarray*}
where $t_{i}$ is a binary explanatory variable defining the treatment
($t_{i}=1$) and control ($t_{i}=0$) groups, and $n_j$ is the 
number of treated observations in category $j$.

\item In conditional prediction models, the average predicted treatment effect
(\texttt{qi\$att.pr}) for the treatment group in category $j$ is
\begin{eqnarray*}
\frac{1}{n_j}\sum_{i:t_{i}=1}^{n_j}[Y_{i}(t_{i}=1)-\widehat{Y_{i}(t_{i}=0)}],
\end{eqnarray*}
where $t_{i}$ is a binary explanatory variable defining the treatment
($t_{i}=1$) and control ($t_{i}=0$) groups, and $n_j$ is the 
number of treated observations in category $j$.

\end{itemize}

\subsubsection{Output Values}

The output of each Zelig command contains useful information which you
may view.  For example, if you run \texttt{z.out <- zelig(y \~\,
  x, model = "oprobit", data)}, then you may examine the available
information in \texttt{z.out} by using \texttt{names(z.out)},
see the {\tt coefficients} by using {\tt z.out\$coefficients}, and
a default summary of information through \texttt{summary(z.out)}.
Other elements available through the {\tt \$} operator are listed
below.

\begin{itemize}
\item From the {\tt zelig()} output object {\tt z.out}, you may
  extract:
   \begin{itemize}
   \item {\tt coefficients}: the named vector of coefficients.   
   \item {\tt fitted.values}: an $n \times J$ matrix of the in-sample
     fitted values.
   \item {\tt predictors}: an $n \times (J-1)$ matrix of the linear
     predictors $x_i \beta_j$.
   \item {\tt residuals}: an $n \times (J-1)$ matrix of the residuals. 
   \item {\tt zeta}: a vector containing the estimated class boundaries. 
   \item {\tt df.residual}: the residual degrees of freedom.  
   \item {\tt df.total}: the total degrees of freedom.
   \item {\tt rss}: the residual sum of squares.  
   \item {\tt y}: an $n \times J$ matrix of the dependent variables.
   \item {\tt zelig.data}: the input data frame if {\tt save.data = TRUE}.  
   \end{itemize}

\item From {\tt summary(z.out)}, you may extract:
\begin{itemize}
  \item {\tt coef3}: a table of the coefficients with their associated
    standard errors and $t$-statistics.
  \item {\tt cov.unscaled}: the variance-covariance matrix. 
  \item {\tt pearson.resid}: an $n \times (m-1)$ matrix of the Pearson residuals.  
\end{itemize}

 \item From the {\tt sim()} output object {\tt s.out}, you may extract
   quantities of interest arranged as arrays.  Available quantities
   are:

   \begin{itemize}
   \item {\tt qi\$ev}: the simulated expected probabilities for the
     specified values of {\tt x}, indexed by simulation $\times$
     quantity $\times$ {\tt x}-observation (for more than one {\tt
       x}-observation).
   \item {\tt qi\$pr}: the simulated predicted values drawn from the
     distribution defined by the expected probabilities, indexed by
     simulation $\times$ {\tt x}-observation.
   \item {\tt qi\$fd}: the simulated first difference in the predicted
     probabilities for the values specified in {\tt x} and {\tt x1},
     indexed by simulation $\times$ quantity $\times$ {\tt
       x}-observation (for more than one {\tt x}-observation).
   \item {\tt qi\$att.ev}: the simulated average expected treatment
     effect for the treated from conditional prediction models.  
   \item {\tt qi\$att.pr}: the simulated average predicted treatment
     effect for the treated from conditional prediction models.  
   \end{itemize}
\end{itemize}


\subsection*{How to Cite the Ordinal Logit Model}
\bibentry{ImaLauKin-ologit11}

\subsection*{How to Cite the Zelig Software Package}
\CiteZelig

\subsection*{See also}
The ordinal probit function is part of the VGAM package by Thomas Yee \citep{YeeHas03}. In addition, advanced users may wish to refer to \texttt{help(vglm)} 
in the VGAM library.  Additional documentation is available at
\url{http://www.stat.auckland.ac.nz/\~\,yee}{http://www.stat.auckland.ac.nz/~yee}.Sample data are from \cite{Martin92}


\bibliographystyle{plain}
\bibliography{ZeligChoice}

\end{document}

